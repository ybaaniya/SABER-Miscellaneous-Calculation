{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open gauge parquet file to get the corresponding pair of model and gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_parquet('/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/gauge_table_2nd_iteration_deDuplicated.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open monthly model fdc zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_s = xr.open_zarr('/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/simulated_monthly_fdc_exceedence.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OPen monthly gauge fdc zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_o = xr.open_zarr('/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/oberved_monthly_fdc.zarr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculates a SFDC for each pairs and also correct sfdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_scalar_fdc(scalar_fdc):\n",
    "    \"\"\"\n",
    "    Adjust scalar values and fill missing p_exceed values\n",
    "    \n",
    "    Parameters:\n",
    "    scalar_fdc: DataFrame with scalar values indexed by p_exceed\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with adjusted scalar values for full p_exceed range (0-100)\n",
    "    \"\"\"\n",
    "    # Create a copy of the original DataFrame to avoid altering it\n",
    "    adjusted_fdc = scalar_fdc.copy()\n",
    "    \n",
    "    # Step 1: Set scalars to 1 if they are:\n",
    "    # - less than 0.001\n",
    "    # - inf (from division by zero)\n",
    "    # - nan (from invalid division)\n",
    "    adjusted_fdc['scalars'] = adjusted_fdc['scalars'].apply(\n",
    "        lambda x: 1 if (x < 0.001) or np.isinf(x) or np.isnan(x) else x\n",
    "    )\n",
    "    \n",
    "    # Step 2: Fill missing p_exceed values down to 0 with scalars set to 1\n",
    "    full_range = pd.Index(range(0, 101))\n",
    "    missing_p_exceed = full_range.difference(adjusted_fdc.index)\n",
    "    \n",
    "    if len(missing_p_exceed) > 0:  # If there are any missing values\n",
    "        missing_rows = pd.DataFrame({'scalars': 1}, index=missing_p_exceed)\n",
    "        adjusted_fdc = pd.concat([adjusted_fdc, missing_rows]).sort_index(ascending=False)\n",
    "    \n",
    "    return adjusted_fdc\n",
    "\n",
    "def extract_and_process_fdc_values(ds_s, ds_o, df_a, index=None):\n",
    "    \"\"\"\n",
    "    Extract FDC values and calculate adjusted scalars for specified index(es)\n",
    "    \n",
    "    Parameters:\n",
    "    ds_s: xarray Dataset - source zarr with rivid dimension\n",
    "    ds_o: xarray Dataset - source zarr with gauge dimension\n",
    "    df_a: DataFrame - mapping between model_id and gauge_id\n",
    "    index: int or None - if provided, process only that index; if None, process all rows\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with rivid, month, p_exceed, and scalar values\n",
    "    \"\"\"\n",
    "    final_rows = []\n",
    "    \n",
    "    # Determine which rows to process\n",
    "    if index is not None:\n",
    "        # Process single index\n",
    "        rows_to_process = [df_a.iloc[index]]\n",
    "    else:\n",
    "        # Process all rows\n",
    "        rows_to_process = [row for _, row in df_a.iterrows()]\n",
    "    \n",
    "    # Process each row\n",
    "    for row in rows_to_process:\n",
    "        rivid = row['model_id']\n",
    "        gauge_id = row['gauge_id']\n",
    "        \n",
    "        try:\n",
    "            # Get values from ds_s (model data)\n",
    "            model_fdc = ds_s.fdc.sel(rivid=rivid).values\n",
    "            \n",
    "            # Get values from ds_o (gauge data)\n",
    "            gauge_fdc = ds_o.fdc.sel(gauge=gauge_id).values\n",
    "            \n",
    "            # Process each month separately\n",
    "            for month in range(1, 13):\n",
    "                # Create monthly DataFrame\n",
    "                month_df = pd.DataFrame({\n",
    "                    'rivid': rivid,\n",
    "                    'month': month,\n",
    "                    'p_exceed': ds_s.p_exceed.values,\n",
    "                    'scalar': model_fdc[:, month-1] / gauge_fdc[:, month-1]\n",
    "                })\n",
    "                \n",
    "                # Sort by p_exceed descending (100 to 0) for adjustment function\n",
    "                month_df = month_df.sort_values('p_exceed', ascending=False)\n",
    "                \n",
    "                # Create DataFrame with scalar values indexed by p_exceed for adjustment\n",
    "                scalar_df = pd.DataFrame({'scalars': month_df['scalar'].values}, \n",
    "                                       index=month_df['p_exceed'])\n",
    "                \n",
    "                # Adjust scalar values using the adjustment function\n",
    "                adjusted_df = adjust_scalar_fdc(scalar_df)\n",
    "                \n",
    "                # Replace original scalar values and ensure all p_exceed values are present\n",
    "                month_df = pd.DataFrame({\n",
    "                    'rivid': rivid,\n",
    "                    'month': month,\n",
    "                    'p_exceed': adjusted_df.index,\n",
    "                    'scalar': adjusted_df['scalars'].values\n",
    "                })\n",
    "                \n",
    "                final_rows.append(month_df)\n",
    "        \n",
    "        except KeyError as e:\n",
    "            print(f\"Warning: Could not find data for rivid {rivid} or gauge_id {gauge_id}\")\n",
    "            continue\n",
    "    \n",
    "    # Combine all data\n",
    "    if final_rows:\n",
    "        result_df = pd.concat(final_rows, ignore_index=True)\n",
    "        # Ensure columns are in desired order\n",
    "        result_df = result_df[['rivid', 'month', 'p_exceed', 'scalar']]\n",
    "        return result_df\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# For single index\n",
    "#df_result_single = extract_and_process_fdc_values(ds_s, ds_o, df_a, index=0)\n",
    "\n",
    "melted_df = extract_and_process_fdc_values(ds_s, ds_o, df_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a zarr file for that sfdc also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZARR functions\n",
    "def create_xarray_zarr(melted_df):\n",
    "    \"\"\"\n",
    "    Convert melted DataFrame to xarray Dataset and save as Zarr\n",
    "    \n",
    "    Parameters:\n",
    "    melted_df (pd.DataFrame): Melted DataFrame with columns 'rivid', 'Month', 'p_exceed', 'fdc'\n",
    "    \"\"\"\n",
    "    # Ensure proper data types\n",
    "    melted_df = melted_df.copy()\n",
    "    melted_df['Month'] = melted_df['Month'].astype(int)\n",
    "    melted_df['p_exceed'] = melted_df['p_exceed'].astype(int)\n",
    "    \n",
    "    # Sort values to ensure consistent ordering\n",
    "    melted_df = melted_df.sort_values(['rivid', 'p_exceed', 'Month'])\n",
    "    \n",
    "    # Get unique values for dimensions\n",
    "    gauges = sorted(melted_df['rivid'].unique())\n",
    "    p_exceed_values = sorted(melted_df['p_exceed'].unique())\n",
    "    months = sorted(melted_df['Month'].unique())\n",
    "    \n",
    "    # Create 3D array with proper shape\n",
    "    shape = (len(gauges), len(p_exceed_values), len(months))\n",
    "    data = np.full(shape, np.nan)\n",
    "    \n",
    "    # Create lookup dictionaries for faster indexing\n",
    "    gauge_idx = {g: i for i, g in enumerate(gauges)}\n",
    "    p_idx = {p: i for i, p in enumerate(p_exceed_values)}\n",
    "    month_idx = {m: i for i, m in enumerate(months)}\n",
    "    \n",
    "    # Fill the 3D array\n",
    "    for _, row in melted_df.iterrows():\n",
    "        i = gauge_idx[row['rivid']]\n",
    "        j = p_idx[row['p_exceed']]\n",
    "        k = month_idx[row['Month']]\n",
    "        data[i, j, k] = row['scalar']\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            'fdc': (['rivid', 'p_exceed', 'month'], data)\n",
    "        },\n",
    "        coords={\n",
    "            'rivid': gauges,\n",
    "            'p_exceed': p_exceed_values,\n",
    "            'month': months\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Chunk the dataset - adjust chunk sizes based on your needs\n",
    "    ds = ds.chunk({\n",
    "        'rivid': min(50, len(gauges)),\n",
    "        'p_exceed': min(101, len(p_exceed_values)),\n",
    "        'month': min(12, len(months))\n",
    "    })\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def save_to_zarr(ds, filename='/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/simulated_sfdc.zarr'):  #the file path is hardcoded here\n",
    "    \"\"\"\n",
    "    Save xarray Dataset to Zarr format and return the absolute path\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): Dataset to save\n",
    "    filename (str): Output filename with path\n",
    "    \n",
    "    Returns:\n",
    "    str: Absolute path to the saved Zarr file\n",
    "    \"\"\"\n",
    "    # Convert to absolute path\n",
    "    abs_path = os.path.abspath(filename)\n",
    "    \n",
    "    # Save to Zarr format without compression\n",
    "    ds.to_zarr(abs_path, mode='w')\n",
    "    \n",
    "    print(f\"Zarr file saved to: {abs_path}\")\n",
    "    return abs_path\n",
    "\n",
    "\n",
    "#Function Call to make a zarr file\n",
    "ds = create_xarray_zarr(melted_df)\n",
    "zarr_path = save_to_zarr(ds)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

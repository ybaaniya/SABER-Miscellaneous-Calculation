{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COL_QSIM = 'Q_sim'  # Simulated flow column\n",
    "\n",
    "def load_zarr_data(hz_path: str) -> xr.Dataset:\n",
    "    \"\"\" Load Zarr dataset containing river flow data. \"\"\"\n",
    "    return xr.open_mfdataset(hz_path, concat_dim='rivid', combine='nested', parallel=True, engine='zarr')\n",
    "\n",
    "def extract_river_flow(hz: xr.Dataset, rivid: int) -> pd.DataFrame:\n",
    "    \"\"\" Extract time series flow data for a given rivid from the Zarr dataset. \"\"\"\n",
    "    sim_flow = hz['Qout'][:, hz.rivid.values == rivid].values\n",
    "    sim_flow_df = pd.DataFrame(sim_flow, index=hz['time'].values, columns=[COL_QSIM])\n",
    "    return sim_flow_df\n",
    "\n",
    "def fdc(flows: np.array, steps: int = 101) -> pd.DataFrame:\n",
    "    \"\"\" Compute flow duration curve (FDC) from flow data. \"\"\"\n",
    "    exceed_prob = np.linspace(0, 100, steps)\n",
    "    fdc_flows = np.nanpercentile(flows, exceed_prob)\n",
    "    df = pd.DataFrame({'p_exceed': exceed_prob, 'fdc': fdc_flows})\n",
    "    return df\n",
    "\n",
    "def compute_monthly_fdcs(hz_path: str, output_file: str = None, num_rivids: int = None):\n",
    "    \"\"\" Compute monthly flow duration curves for each rivid and save or display results. \"\"\"\n",
    "    hz = load_zarr_data(hz_path)\n",
    "    rivids = hz.rivid.values  # Get all river IDs in the dataset\n",
    "    \n",
    "    if num_rivids is not None:\n",
    "        rivids = rivids[:num_rivids]\n",
    "    print(f\"Total rivids being processed: {len(rivids)}\")\n",
    "    \n",
    "    all_fdc_data = []\n",
    "    \n",
    "    for rivid in rivids:\n",
    "        print(f\"Processing rivid: {rivid}\")\n",
    "        sim_flow_df = extract_river_flow(hz, rivid)\n",
    "        sim_flow_df.index = pd.to_datetime(sim_flow_df.index)\n",
    "        # Apply the year filter for the range 1941-2025\n",
    "        sim_flow_df = sim_flow_df[(sim_flow_df.index.year >= 1941) & (sim_flow_df.index.year <= 2025)]\n",
    "        \n",
    "        for month in range(1, 13):\n",
    "            monthly_flow = sim_flow_df[sim_flow_df.index.month == month].dropna().clip(lower=0)\n",
    "            #print(monthly_flow)\n",
    "            if not monthly_flow.empty:\n",
    "                #print(f\"  - Processing month: {month} for rivid {rivid} with {len(monthly_flow)} records\")\n",
    "                fdc_df = fdc(monthly_flow[COL_QSIM].values)\n",
    "                fdc_df['rivid'] = rivid\n",
    "                fdc_df['Month'] = month\n",
    "                all_fdc_data.append(fdc_df)\n",
    "            else:\n",
    "                print(f\"  - No data for rivid {rivid} in month {month}\")\n",
    "\n",
    "    all_fdc_df = pd.concat(all_fdc_data, ignore_index=True)\n",
    "    \n",
    "    if output_file:\n",
    "        all_fdc_df.to_parquet(output_file)\n",
    "        #print(f'Saved FDC data to {output_file}')\n",
    "    else:\n",
    "        print(all_fdc_df)\n",
    "    \n",
    "    hz.close()\n",
    "\n",
    "# Usage\n",
    "hz_path = \"/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/2nd_iteration_simulation_data.zarr\"  # Replace with the path to your Zarr file\n",
    "output_file = \"/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/tables/monthly_simulated_FDC.parquet\"  # Set to None if you don't want to save to a file during testing\n",
    "num_rivids = None  # mention number of rivids for testing or None for using all rivids\n",
    "\n",
    "compute_monthly_fdcs(hz_path, output_file=output_file, num_rivids=num_rivids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_df = pd.read_parquet('/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/tables/monthly_simulated_FDC.parquet')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert the parquet to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ZARR functions\n",
    "def create_xarray_zarr(melted_df):\n",
    "    \"\"\"\n",
    "    Convert melted DataFrame to xarray Dataset and save as Zarr\n",
    "    \n",
    "    Parameters:\n",
    "    melted_df (pd.DataFrame): Melted DataFrame with columns 'rivid', 'Month', 'p_exceed', 'fdc'\n",
    "    \"\"\"\n",
    "    # Ensure proper data types\n",
    "    melted_df = melted_df.copy()\n",
    "    melted_df['Month'] = melted_df['Month'].astype(int)\n",
    "    melted_df['p_exceed'] = melted_df['p_exceed'].astype(int)\n",
    "    \n",
    "    # Sort values to ensure consistent ordering\n",
    "    melted_df = melted_df.sort_values(['rivid', 'p_exceed', 'Month'])\n",
    "    \n",
    "    # Get unique values for dimensions\n",
    "    gauges = sorted(melted_df['rivid'].unique())\n",
    "    p_exceed_values = sorted(melted_df['p_exceed'].unique())\n",
    "    months = sorted(melted_df['Month'].unique())\n",
    "    \n",
    "    # Create 3D array with proper shape\n",
    "    shape = (len(gauges), len(p_exceed_values), len(months))\n",
    "    data = np.full(shape, np.nan)\n",
    "    \n",
    "    # Create lookup dictionaries for faster indexing\n",
    "    gauge_idx = {g: i for i, g in enumerate(gauges)}\n",
    "    p_idx = {p: i for i, p in enumerate(p_exceed_values)}\n",
    "    month_idx = {m: i for i, m in enumerate(months)}\n",
    "    \n",
    "    # Fill the 3D array\n",
    "    for _, row in melted_df.iterrows():\n",
    "        i = gauge_idx[row['rivid']]\n",
    "        j = p_idx[row['p_exceed']]\n",
    "        k = month_idx[row['Month']]\n",
    "        data[i, j, k] = row['fdc']\n",
    "    \n",
    "    # Create xarray Dataset\n",
    "    ds = xr.Dataset(\n",
    "        {\n",
    "            'fdc': (['rivid', 'p_exceed', 'month'], data)\n",
    "        },\n",
    "        coords={\n",
    "            'rivid': gauges,\n",
    "            'p_exceed': p_exceed_values,\n",
    "            'month': months\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Chunk the dataset - adjust chunk sizes based on your needs\n",
    "    ds = ds.chunk({\n",
    "        'rivid': min(50, len(gauges)),\n",
    "        'p_exceed': min(101, len(p_exceed_values)),\n",
    "        'month': min(12, len(months))\n",
    "    })\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def save_to_zarr(ds, filename='/Users/yubinbaaniya/Documents/WORLD BIAS/saber workdir/simulated_monthly_fdc_exceedence.zarr'):  #the file path is hardcoded here\n",
    "    \"\"\"\n",
    "    Save xarray Dataset to Zarr format and return the absolute path\n",
    "    \n",
    "    Parameters:\n",
    "    ds (xarray.Dataset): Dataset to save\n",
    "    filename (str): Output filename with path\n",
    "    \n",
    "    Returns:\n",
    "    str: Absolute path to the saved Zarr file\n",
    "    \"\"\"\n",
    "    # Convert to absolute path\n",
    "    abs_path = os.path.abspath(filename)\n",
    "    \n",
    "    # Save to Zarr format without compression\n",
    "    ds.to_zarr(abs_path, mode='w')\n",
    "    \n",
    "    print(f\"Zarr file saved to: {abs_path}\")\n",
    "    return abs_path\n",
    "\n",
    "\n",
    "#Function Call to make a zarr file\n",
    "ds = create_xarray_zarr(melted_df)\n",
    "zarr_path = save_to_zarr(ds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
